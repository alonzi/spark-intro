# spark-intro
This repo contains materials for a spark introduction

## Who am I?
* [Senior Research Data Scientist with the Data Science Institute and UVA Library](https://dsi.virginia.edu/people/peter-alonzi)
* I like to be interrupted with questions! Please jump right in.

## Welcome to the UVA Library
* [Research Data Services](https://data.library.virginia.edu/)
* [Workshop Series](https://data.library.virginia.edu/training/)
  * Data Storage Best Practices (Bill Corey)	Tuesday, 11/6	14:00 â€“ 15:30	Brown 133
  
## Getting Spark 
* [Amazon Web Services Sagemaker](https://us-east-1.signin.aws.amazon.com/oauth?SignatureVersion=4&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJMOATPLHVSJ563XQ&X-Amz-Date=2018-10-15T15%3A37%3A38.105Z&X-Amz-Signature=16712fc21b036c069bd01eb7d77e0ea3bfc2db6308ea89c567b58c63f917f030&X-Amz-SignedHeaders=host&client_id=arn%3Aaws%3Aiam%3A%3A015428540659%3Auser%2Fhomepage&nc2=h_ct&redirect_uri=https%3A%2F%2Fconsole.aws.amazon.com%2Fconsole%2Fhome%3Fnc2%3Dh_ct%26src%3Dheader-signin%26state%3DhashArgs%2523%26isauthcode%3Dtrue&response_type=code&src=header-signin&state=hashArgs%23)
  * This link lets you sign into the AWS console
    * Account ID = open-data-lab
  * See the handout for IAM user name / password

## What is Spark?
"Apache Spark is an open-source distributed general-purpose cluster-computing framework." ~ wikipedia
  * cluster programming interface
  * data parallelization
  * v1 2014-05-26
  * v2 2016-07-26
  * current v2.4
  
# Goals for Today
1. Get everyone running on spark
2. Get comfortable with spark
3. Learn how to look up help

## Outline
1. AWS Sagemaker orientation
2. Setting up the spark environment
3. Reading in data from a file
4. Using SQL
5. Database operations
6. A sample calculation



# Using Spark powered by AWS
* [login to the AWS console](https://us-east-1.signin.aws.amazon.com/oauth?SignatureVersion=4&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJMOATPLHVSJ563XQ&X-Amz-Date=2018-10-15T15%3A37%3A38.105Z&X-Amz-Signature=16712fc21b036c069bd01eb7d77e0ea3bfc2db6308ea89c567b58c63f917f030&X-Amz-SignedHeaders=host&client_id=arn%3Aaws%3Aiam%3A%3A015428540659%3Auser%2Fhomepage&nc2=h_ct&redirect_uri=https%3A%2F%2Fconsole.aws.amazon.com%2Fconsole%2Fhome%3Fnc2%3Dh_ct%26src%3Dheader-signin%26state%3DhashArgs%2523%26isauthcode%3Dtrue&response_type=code&src=header-signin&state=hashArgs%23)
* search services for 'sagemaker'
* left hand side click 'notebook instances'
* in the spark-education row under actions click 'open'
* upper right corner choose new -> conda_python3
* this is the notebook you will work in for the session, please change the name of the notebook to your name

## Setting up your environment
* 



# Ways to Practice
1. Write some analysis in spark
2. Ask a friend to review it

* Beginning
  * 
* Intermediate
  * 
* Expert
  * 







